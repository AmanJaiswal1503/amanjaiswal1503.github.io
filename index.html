<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163784922-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) };
        //JS: "||" is OR function, push() is append()
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-163784922-1');
    </script>
    <title>Aman Jaiswal</title>
    <meta name="author" content="Aman Jaiswal">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="data/yashcircle.jpg">
</head>

<body>

    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:5%;width:40%;max-width:40%">
                                    <a href="data/aman.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                            src="data/aman.jpg" class="hoverZoomLink"></a>
                                </td>
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Aman Jaiswal</name>
                                    </p>
                                    <p> I am currently working as a <strong>Research Assistant</strong> in MANAS Lab, IIT Mandi in
                                        <a href="https://faculty.iitmandi.ac.in/~aditya/">Prof Aditya Nigam's</a>
                                        group, where I am working on <strong>gallbladder cancer (GBC) detection</strong> (in
                                        collaboration with
                                        <a href="https://www.cse.iitd.ac.in/~chetan/">Prof. Chetan Arora</a>,
                                        IIT Delhi and
                                        <a href="https://www.linkedin.com/in/dr-pankaj-gupta-8ab31323">Prof. Dr. Pankaj
                                            Gupta</a>,
                                        SGPGI Chandigarh).

                                    </p>
                                    <p>
                                        I also work as a <strong> Senior Machine Learning Engineer</strong> at <a
                                            href="https://www.entrupy.com">
                                            Entrupy</a>,
                                        where I work with the India-ML team to develop solutions for <strong>finerprinting and
                                        authenticating</strong>
                                        luxury/high-value goods. Prior to this, I worked as a Technological Account
                                        Manager at <a href="https://www.g7cr.in/">G7 CR Technologies</a>.
                                    </p>

                                    <p>I completed my Bachelor of Technology in Computer Science and Engineering (CSE) from <a href="http://iitdh.ac.in">Indian
                                            Institute of
                                            Technology Dharwad</a>. I have had the opportunity to work with Prof Aditya
                                        Nigam</a>
                                        in the summer of 2019. I have also collaborated with <a
                                            href="https://researcher.watson.ibm.com/researcher/view.php?person=in-vmunig10">
                                            Mr. Vitobha Munigala </a> of
                                        <a href='https://www.research.ibm.com/labs/india/'>IBM Research Labs,
                                            Benagaluru</a> under IBM's Global Remote Mentorship Programme.
                                    </p>

                                    <p> <strong>I want to improve healthcare by making computers see, talk and act. </strong></p>

                                    <p>
                                        If you have any questions / want to collaborate / discuss new ideas, feel free
                                        to send me an <a href="mailto:aman.jaiswal.1503@gmail.com">email</a>!
                                    </p>

                                    <p style="text-align:center">
                                        <a href="https://scholar.google.com/citations?user=tarYZ3oAAAAJ&hl=en">Google
                                            Scholar</a> &nbsp/&nbsp
                                        <a href="mailto:aman.jaiswal.1503@gmail.com">Email</a> &nbsp/&nbsp
                                        <a href="data/cv-aman.pdf"
                                            onclick="ga('send', 'event', 'Videos', 'play', 'Fall Campaign')">CV</a>
                                        &nbsp/&nbsp
                                        <a href="https://github.com/AmanJaiswal1503"> Github </a> &nbsp/&nbsp
                                        <a href="https://twitter.com/aman_jaiswal_03">Twitter</a> &nbsp/&nbsp
                                        <a href="https://linkedin.com/in/aman-jaiswal-8b008415b/"> LinkedIn </a>
                                    </p>
                                </td>

                            </tr>
                        </tbody>
                    </table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>News</heading>
                                    <ul>
                                        <li> [June 2024] Joined MANAS Lab, IIT Mandi as a Research Assistant (in Prof
                                            Adita Nigam's group).</li>
                                        <li> [June 2023] Patent published - <a
                                                href="https://patents.google.com/patent/WO2023114435A1/en">Macroscopic
                                                fingerprint</a>.</li>
                                        <li> [April 2023] Promoted to Senior Machine Learning Engineer at Entrupy.</li>
                                        <li> [August 2022] Patent granted - <a
                                                href="https://patents.google.com/patent/US11430152B1/en">Monocular pose
                                                estimation and correction</a> for sneaker authentication.</li>
                                        <li> [April 2022] Promoted to Machine Learnering Engineer II at Entrupy.</li>
                                        <li> [Sep 2020] Joined Entrupy as a Machine Learning Engineer. </li>
                                        <li> [May 2020] Joined G7CR Technologies as a Cloud Solution Architect. </li>
                                        <li> [April 2020] Graduated from IIT Dharwad. </li>
                                        <li> [Mar 2020] <a
                                                href="https://ieeexplore.ieee.org/document/9206921">En-VStegNET</a>
                                            accepted to <a href="https://wcci2020.org/">IJCNN'20</a> (in association
                                            with IIT Mandi).</li>
                                        <li> [August 2019] Selected for IBM's Global Research Mentorship Programme.</li>
                                        <li> [May 2019] Started as a research intern at IIT Mandi. </li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td
                                    style="padding-left:20px;padding-right:20px;padding-top:20px;width:25%;vertical-align:middle">
                                    <heading>Publications</heading>
                                </td>
                            </tr>


                            <tr>
                                <td style="padding:30px;width:25%;vertical-align:middle">
                                    <img src="data/EnVStegNet.png">
                                </td>

                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9206921">
                                        <papertitle>En-VStegNET: Video Steganography using spatio-temporal feature
                                            enhancement with 3D-CNN and Hourglass</papertitle>
                                    </a>
                                    <br>
                                    <strong>Aman Jaiswal</strong>,
                                    <a href="https://www.linkedin.com/in/csksuraj17">Suraj Kumar</a>,
                                    <a href="https://faculty.iitmandi.ac.in/~aditya/">Aditya Nigam</a>
                                    <br>
                                    <em>IJCNN, 2020</em>
                                    <br>
                                    <a
                                        href="http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_WCCI_2020/IJCNN/Papers/N-21848.pdf">paper</a>
                                    /
                                    <a href="https://www.youtube.com/watch?v=h_Nob_qGRZo">presentation</a>
                                    <br>
                                    <p></p>
                                    <p>We propose an Enhanced-VStegNET for full-video steganography,
                                        that outperforms the current SOTA VStegNET both quantitavily and qualitatively
                                        by modifying the architectures
                                        of the hiding and revealing networks that helps encode information more covertly
                                        and decode information more reliably.</p>
                                </td>
                            </tr>



                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td
                                    style="padding-left:20px;padding-right:20px;padding-top:20px;width:25%;vertical-align:middle">
                                    <heading>Patents</heading>
                                </td>
                            </tr>


                            <tr>
                                <td style="padding:30px;width:25%;vertical-align:middle">
                                    <img src="data/Macroscopic_fingerprinting.png">
                                </td>

                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="https://patents.google.com/patent/WO2023114435A1/en">
                                        <papertitle>Macroscopic Fingerprinting</papertitle>
                                    </a>
                                    <br>
                                    <a href="https://www.linkedin.com/in/csksuraj17">Hemanth Sangappa</a>,
                                    <strong>Aman Jaiswal</strong>,
                                    <a href="https://www.linkedin.com/in/csksuraj17">Akhilesh Yadav</a>,
                                    <a href="https://www.linkedin.com/in/csksuraj17">Pratik Likhar</a>,
                                    <a href="https://faculty.iitmandi.ac.in/~aditya/">Ashlesh Sharma</a>
                                    <br>
                                    <em>Patent Application No. - WO 2023114435A1 (Published) </em>
                                    <p></p>
                                    <p>
                                        Various embodiments of an apparatus, methods, systems and computer program
                                        products described herein are directed to a Fingerprint Engine that registers a
                                        reference image portraying a physical instance of an object. The Fingerprint
                                        Engine captures a query image portraying a physical instance of a target object.
                                        The Fingerprint Engine compares the reference image and the query image. The
                                        Fingerprint Engine determines an authenticity of the target object based on
                                        detecting a match between the reference image and the query image.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:25%;vertical-align:middle">
                                    <img src="data/pose_correction.png">
                                </td>

                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="https://patents.google.com/patent/US11430152B1/en">
                                        <papertitle>Monocular Pose Estimation and Correction</papertitle>
                                    </a>(for sneaker authentication)
                                    <br>
                                    <a href="https://www.linkedin.com/in/csksuraj17">Hemanth Sangappa</a>,
                                    <strong>Aman Jaiswal</strong>,
                                    <a href="https://www.linkedin.com/in/csksuraj17">Rohan Sheelvant</a>,
                                    <a href="https://faculty.iitmandi.ac.in/~aditya/">Ashlesh Sharma</a>
                                    <br>
                                    <em>Patent Application No. - US 11430152B1 (Granted) </em>
                                    <p></p>
                                    <p>
                                        Various embodiments are directed to a Pose Correction
                                        Engine ( “ Engine ” ) . The Engine generates a reference image of the object of
                                        interest . The reference image portrays the
                                        object of interest oriented according to a first pose . The
                                        Engine receives a source image of an instance of the object . The source image
                                        portrays the instance of the object oriented
                                        according to a variation of the first pose . The Engine determines a difference
                                        between the first pose of the refer
                                        ence image and the variation of the first pose of the source image . The Engine
                                        identifies , based on the determined
                                        difference , one or portions of a three - dimensional ( 3D ) map of a shape of
                                        the
                                        object obscured by the variation of the first
                                        pose portrayed in the source image . The Engine generates a
                                        pose corrected image of the instance of the object that
                                        portrays at least a portion of the source image and at least the
                                        identified portion of the 3D map of the shape of the object.

                                        <br><br>

                                        Related Patent: <a
                                            href="https://patents.google.com/patent/US20230143551A1/en">Pose
                                            Estimation and Correction</a>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Additional Research Experience</heading>
                                    <p class="content">
                                    <ul>
                                        <li><b><i>Cross-domain Matching:</i></b> Worked on developing a recognition
                                            systems that can
                                            perform cross-sensor/cross-spectral IRIS identification.
                                        </li>
                                        <br>
                                        <li><b><i>Unconstrained Ear Matching:</i></b> Worked on developing a novel capsule-network based neural network architecture to perform ear-matching on the challenging
                                            UERC (Unconstrained Ear Recognition Challenge) dataset, improving upon the current state-of-the-art method
                                            for the same..
                                        </li>
                                        <br>
                                        <li><b><i>Video Colorisation:</i></b> Implemented and extended Pix2Pix, Colorful Image Colorization and other image colorization research papers to
                                            videos by using 3D CNN instead of 2D CNN and introducing a temporal loss component.
                                        </li>
                                    </ul>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!--
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Fun</heading>
                        <p class="content">
                          <ul>
                              <li></li>
                          </ul>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            -->


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:small;">
                                        I borrowed this template from Jon Barron's
                                        <a href="https://github.com/jonbarron/jonbarron_website"> website</a>.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </table>
</body>

</html>
